{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "823f9241-eb6c-4e19-bbe7-9253b0f2d930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using median trial length: 118\n",
      "âœ… Abhay Cascaded Shape: (100, 4248)\n",
      "âœ… Arjun Cascaded Shape: (100, 4248)\n",
      "ðŸŽ¯ PCA complete\n",
      "Abhay PCA shape: Train (70, 20), Test (30, 20)\n",
      "Arjun PCA shape: Train (70, 21), Test (30, 21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# === Column Definition ===\n",
    "expected_columns = [\n",
    "    'time', 'palm_position_x', 'palm_position_y', 'palm_position_z',\n",
    "    'palm_normal_x', 'palm_normal_y', 'palm_normal_z',\n",
    "    'palm_direction_x', 'palm_direction_y', 'palm_direction_z',\n",
    "    'hand_grab_angle', 'hand_grab_strength', 'hand_pinch_angle', 'hand_pinch_strength',\n",
    "    'thumb_extension', 'index_extension', 'middle_extension', 'ring_extension', 'pinky_extension'\n",
    "]\n",
    "\n",
    "# === Utilities ===\n",
    "def is_row_empty(row):\n",
    "    return all(pd.isna(cell) or (isinstance(cell, str) and cell.strip() == '') for cell in row)\n",
    "\n",
    "def trim_leading_empty_rows(df):\n",
    "    for i in range(len(df)):\n",
    "        if not is_row_empty(df.iloc[i]):\n",
    "            return df.iloc[i:].reset_index(drop=True)\n",
    "    return pd.DataFrame(columns=df.columns)\n",
    "\n",
    "def trim_trailing_empty_rows(df):\n",
    "    for i in reversed(range(len(df))):\n",
    "        if not is_row_empty(df.iloc[i]):\n",
    "            return df.iloc[:i+1].reset_index(drop=True)\n",
    "    return pd.DataFrame(columns=df.columns)\n",
    "\n",
    "def find_trial_split_index(df):\n",
    "    for i in range(len(df)):\n",
    "        if is_row_empty(df.iloc[i]):\n",
    "            if i+1 < len(df) and is_row_empty(df.iloc[i+1]):\n",
    "                return i\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def split_trials(df):\n",
    "    df = trim_leading_empty_rows(df)\n",
    "    split_idx = find_trial_split_index(df)\n",
    "    if split_idx is None:\n",
    "        return df.reset_index(drop=True), pd.DataFrame(columns=df.columns)\n",
    "    trial1 = df.iloc[:split_idx]\n",
    "    trial2 = df.iloc[split_idx+1:]\n",
    "    trial1 = trim_trailing_empty_rows(trial1)\n",
    "    trial2 = trim_leading_empty_rows(trial2)\n",
    "    trial2 = trim_trailing_empty_rows(trial2)\n",
    "    return trial1.reset_index(drop=True), trial2.reset_index(drop=True)\n",
    "\n",
    "def resample_by_time(df, time_col, target_rows):\n",
    "    df = df.copy()\n",
    "    df[time_col] = pd.to_numeric(df[time_col], errors='coerce')\n",
    "    df = df.dropna(subset=[time_col])\n",
    "    df = df.drop_duplicates(subset=time_col)\n",
    "    for col in df.columns:\n",
    "        if col != time_col:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    df = df.set_index(time_col)\n",
    "    new_time_index = np.linspace(df.index.min(), df.index.max(), target_rows)\n",
    "    df_resampled = df.reindex(new_time_index)\n",
    "    df_resampled = df_resampled.interpolate(method='linear', axis=0).reset_index()\n",
    "    df_resampled.rename(columns={'index': time_col}, inplace=True)\n",
    "    return df_resampled\n",
    "\n",
    "def safe_resample(df_list, time_col, target_rows):\n",
    "    return [\n",
    "        resample_by_time(df, time_col, target_rows)\n",
    "        for df in df_list\n",
    "        if time_col in df.columns and not df.empty\n",
    "    ]\n",
    "\n",
    "def cascade_gesture(trial1, trial2):\n",
    "    trial1 = trial1[[col for col in trial1.columns if not col.endswith(\"time\")]]\n",
    "    trial2 = trial2[[col for col in trial2.columns if not col.endswith(\"time\")]]\n",
    "    vector = np.concatenate([trial1.to_numpy().T.flatten(), trial2.to_numpy().T.flatten()])\n",
    "    return pd.DataFrame([vector])\n",
    "\n",
    "# === MAIN PROCESSING ===\n",
    "input_folder = r\"C:\\Users\\Abhay\\Downloads\\ExportedSheets\"\n",
    "csv_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]\n",
    "\n",
    "all_abhay_trial1, all_abhay_trial2 = [], []\n",
    "all_arjun_trial1, all_arjun_trial2 = [], []\n",
    "\n",
    "for file in csv_files:\n",
    "    path = os.path.join(input_folder, file)\n",
    "    try:\n",
    "        df = pd.read_csv(path, header=None)\n",
    "        df = df.iloc[1:].reset_index(drop=True)\n",
    "        df = df.iloc[:, :39]  # 19 Abhay + 1 blank + 19 Arjun\n",
    "\n",
    "        abhay_df = df.iloc[:, :19].copy()\n",
    "        arjun_df = df.iloc[:, 20:].copy()\n",
    "\n",
    "        abhay_df.columns = [f\"Abhay_{col}\" for col in expected_columns]\n",
    "        arjun_df.columns = [f\"Arjun_{col}\" for col in expected_columns]\n",
    "\n",
    "        abhay_df.dropna(axis=1, how='all', inplace=True)\n",
    "        arjun_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "        abhay_t1, abhay_t2 = split_trials(abhay_df)\n",
    "        arjun_t1, arjun_t2 = split_trials(arjun_df)\n",
    "\n",
    "        all_abhay_trial1.append(abhay_t1)\n",
    "        all_abhay_trial2.append(abhay_t2)\n",
    "        all_arjun_trial1.append(arjun_t1)\n",
    "        all_arjun_trial2.append(arjun_t2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# === Compute median trial length ===\n",
    "all_lengths = [len(df) for df in all_abhay_trial1 + all_abhay_trial2 + all_arjun_trial1 + all_arjun_trial2]\n",
    "median_len = int(np.median(all_lengths))\n",
    "print(f\"Using median trial length: {median_len}\")\n",
    "\n",
    "# === Resample all trials ===\n",
    "all_abhay_trial1 = safe_resample(all_abhay_trial1, 'Abhay_time', median_len)\n",
    "all_abhay_trial2 = safe_resample(all_abhay_trial2, 'Abhay_time', median_len)\n",
    "all_arjun_trial1 = safe_resample(all_arjun_trial1, 'Arjun_time', median_len)\n",
    "all_arjun_trial2 = safe_resample(all_arjun_trial2, 'Arjun_time', median_len)\n",
    "\n",
    "# === Cascade trial1 + trial2 into gesture-level rows ===\n",
    "cascaded_abhay = [cascade_gesture(t1, t2) for t1, t2 in zip(all_abhay_trial1, all_abhay_trial2)]\n",
    "cascaded_arjun = [cascade_gesture(t1, t2) for t1, t2 in zip(all_arjun_trial1, all_arjun_trial2)]\n",
    "\n",
    "full_abhay_df = pd.concat(cascaded_abhay, ignore_index=True)\n",
    "full_arjun_df = pd.concat(cascaded_arjun, ignore_index=True)\n",
    "\n",
    "print(f\"âœ… Abhay Cascaded Shape: {full_abhay_df.shape}\")\n",
    "print(f\"âœ… Arjun Cascaded Shape: {full_arjun_df.shape}\")\n",
    "\n",
    "# === Normalize using Min-Max Scaler ===\n",
    "minmax_abhay = MinMaxScaler()\n",
    "normalized_abhay = pd.DataFrame(minmax_abhay.fit_transform(full_abhay_df))\n",
    "\n",
    "minmax_arjun = MinMaxScaler()\n",
    "normalized_arjun = pd.DataFrame(minmax_arjun.fit_transform(full_arjun_df))\n",
    "\n",
    "# === Split into Train/Test ===\n",
    "train_abhay_df = normalized_abhay.iloc[:70].reset_index(drop=True)\n",
    "test_abhay_df = normalized_abhay.iloc[70:].reset_index(drop=True)\n",
    "\n",
    "train_arjun_df = normalized_arjun.iloc[:70].reset_index(drop=True)\n",
    "test_arjun_df = normalized_arjun.iloc[70:].reset_index(drop=True)\n",
    "\n",
    "# === PCA ===\n",
    "pca_abhay = PCA(n_components=0.95)\n",
    "train_abhay_pca = pd.DataFrame(pca_abhay.fit_transform(train_abhay_df))\n",
    "test_abhay_pca = pd.DataFrame(pca_abhay.transform(test_abhay_df))\n",
    "\n",
    "pca_arjun = PCA(n_components=0.95)\n",
    "train_arjun_pca = pd.DataFrame(pca_arjun.fit_transform(train_arjun_df))\n",
    "test_arjun_pca = pd.DataFrame(pca_arjun.transform(test_arjun_df))\n",
    "\n",
    "# === Final Output Summary ===\n",
    "print(\"ðŸŽ¯ PCA complete\")\n",
    "print(f\"Abhay PCA shape: Train {train_abhay_pca.shape}, Test {test_abhay_pca.shape}\")\n",
    "print(f\"Arjun PCA shape: Train {train_arjun_pca.shape}, Test {test_arjun_pca.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c07a17-1586-4a4b-9284-08337c92e70c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
